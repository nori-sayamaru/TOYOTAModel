{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPvBp2xrQLkwyxcAb7hZzgU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nori-sayamaru/TOYOTAModel/blob/main/TOYOTAModel%F0%9F%84%AC4_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pY_oCMW2K2n6"
      },
      "outputs": [],
      "source": [
        "# --- Install ---\n",
        "!pip -q install -U \"transformers>=4.41.0,<6.0.0\" \"accelerate\" \"gradio\" \"pillow\"\n",
        "\n",
        "# --- Drive mount (B: Google Driveに保存) ---\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "# --- Imports ---\n",
        "import os, json, uuid\n",
        "from datetime import datetime\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import gradio as gr\n",
        "from transformers import AutoProcessor, BlipForConditionalGeneration\n",
        "\n",
        "# --- Paths (Drive) ---\n",
        "BASE_DIR = \"/content/drive/MyDrive/traffic_semantic_log\"\n",
        "IMG_DIR  = os.path.join(BASE_DIR, \"images\")\n",
        "LOG_PATH = os.path.join(BASE_DIR, \"log.jsonl\")\n",
        "os.makedirs(IMG_DIR, exist_ok=True)\n",
        "\n",
        "# --- Model (BLIP caption) ---\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "processor = AutoProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\").to(device)\n",
        "model.eval()\n",
        "\n",
        "def caption_image(pil_image: Image.Image) -> str:\n",
        "    inputs = processor(images=pil_image, return_tensors=\"pt\").to(device)\n",
        "    with torch.inference_mode():\n",
        "        out = model.generate(**inputs, max_new_tokens=40)\n",
        "    return processor.decode(out[0], skip_special_tokens=True)\n",
        "\n",
        "# --- Heuristic \"semantic distillation\" (軽量スコアリング) ---\n",
        "# ここは「後で学習に置き換える部分」。今は軽いルールで“電位差”を外付け。\n",
        "KEYWORDS = {\n",
        "    \"pedestrian\": [\"pedestrian\", \"person\", \"people\", \"man\", \"woman\", \"child\", \"crowd\"],\n",
        "    \"bicycle\":    [\"bicycle\", \"bike\", \"cyclist\"],\n",
        "    \"car\":        [\"car\", \"vehicle\", \"truck\", \"bus\", \"van\", \"motorcycle\"],\n",
        "    \"crosswalk\":  [\"crosswalk\", \"zebra crossing\", \"crossing\"],\n",
        "    \"traffic_light\": [\"traffic light\", \"signal light\", \"stoplight\"],\n",
        "    \"red\":        [\"red light\", \"red signal\"],\n",
        "    \"construction\":[\"construction\", \"road work\", \"cones\", \"barrier\"],\n",
        "    \"intersection\":[\"intersection\", \"junction\", \"crossroad\"],\n",
        "    \"night_rain\": [\"night\", \"dark\", \"rain\", \"fog\", \"snow\"],\n",
        "}\n",
        "\n",
        "def contains_any(text: str, words: list[str]) -> bool:\n",
        "    t = text.lower()\n",
        "    return any(w in t for w in words)\n",
        "\n",
        "def distill_and_score(caption: str):\n",
        "    # 観測フラグ\n",
        "    obs = {\n",
        "        \"pedestrian\": contains_any(caption, KEYWORDS[\"pedestrian\"]),\n",
        "        \"bicycle\": contains_any(caption, KEYWORDS[\"bicycle\"]),\n",
        "        \"car\": contains_any(caption, KEYWORDS[\"car\"]),\n",
        "        \"crosswalk\": contains_any(caption, KEYWORDS[\"crosswalk\"]),\n",
        "        \"traffic_light\": contains_any(caption, KEYWORDS[\"traffic_light\"]),\n",
        "        \"red\": contains_any(caption, KEYWORDS[\"red\"]),\n",
        "        \"construction\": contains_any(caption, KEYWORDS[\"construction\"]),\n",
        "        \"intersection\": contains_any(caption, KEYWORDS[\"intersection\"]),\n",
        "        \"low_visibility\": contains_any(caption, KEYWORDS[\"night_rain\"]),\n",
        "    }\n",
        "\n",
        "    # スコア（0〜1にクリップ）\n",
        "    stop = 0.20\n",
        "    slow = 0.20\n",
        "    go   = 0.20\n",
        "\n",
        "    reasons_stop = []\n",
        "    reasons_slow = []\n",
        "    reasons_go   = []\n",
        "\n",
        "    if obs[\"red\"]:\n",
        "        stop += 0.70; reasons_stop.append(\"信号が赤っぽい記述（停止を強化）\")\n",
        "    if obs[\"pedestrian\"] and obs[\"crosswalk\"]:\n",
        "        stop += 0.55; reasons_stop.append(\"横断歩道＋歩行者らしき記述（停止寄り）\")\n",
        "    if obs[\"pedestrian\"] and not obs[\"crosswalk\"]:\n",
        "        slow += 0.45; reasons_slow.append(\"歩行者らしき記述（徐行寄り）\")\n",
        "    if obs[\"bicycle\"]:\n",
        "        slow += 0.35; reasons_slow.append(\"自転車らしき記述（徐行寄り）\")\n",
        "    if obs[\"construction\"]:\n",
        "        slow += 0.40; reasons_slow.append(\"工事・コーン等の記述（徐行寄り）\")\n",
        "    if obs[\"intersection\"]:\n",
        "        slow += 0.25; reasons_slow.append(\"交差点らしき記述（徐行寄り）\")\n",
        "    if obs[\"low_visibility\"]:\n",
        "        slow += 0.25; reasons_slow.append(\"視界が悪そう（夜/雨/霧などの記述）（安全側）\")\n",
        "\n",
        "    # 進行は “危険要素が少ない” ときに上がる（逆算）\n",
        "    risk = (stop + slow) - 0.40\n",
        "    go += max(0.0, 0.35 - risk)\n",
        "    if go > 0.35:\n",
        "        reasons_go.append(\"危険要素キーワードが少なめ（進行寄り）\")\n",
        "\n",
        "    # クリップ＆正規化\n",
        "    stop = max(0.0, min(1.0, stop))\n",
        "    slow = max(0.0, min(1.0, slow))\n",
        "    go   = max(0.0, min(1.0, go))\n",
        "\n",
        "    s = stop + slow + go\n",
        "    stop, slow, go = stop/s, slow/s, go/s\n",
        "\n",
        "    # 結論\n",
        "    action = max([(\"停止\", stop), (\"徐行\", slow), (\"進行\", go)], key=lambda x: x[1])[0]\n",
        "\n",
        "    return obs, {\"停止\": stop, \"徐行\": slow, \"進行\": go}, {\n",
        "        \"停止\": reasons_stop[:3],\n",
        "        \"徐行\": reasons_slow[:3],\n",
        "        \"進行\": reasons_go[:3],\n",
        "    }, action\n",
        "\n",
        "def bar(p: float, width: int = 18) -> str:\n",
        "    filled = int(round(p * width))\n",
        "    return \"█\" * filled + \"░\" * (width - filled)\n",
        "\n",
        "def render_panel(caption: str, scores: dict, reasons: dict, action: str) -> str:\n",
        "    # 図っぽい表示（軽量）\n",
        "    lines = []\n",
        "    lines.append(\"## スコアカード\")\n",
        "    for k in [\"停止\", \"徐行\", \"進行\"]:\n",
        "        p = scores[k]\n",
        "        lines.append(f\"- **{k}**  {bar(p)}  {p:.2f}\")\n",
        "    lines.append(\"\")\n",
        "    lines.append(f\"## 結論（暫定）: **{action}**\")\n",
        "    lines.append(\"\")\n",
        "    lines.append(\"## 理由ツリー（上位3つまで）\")\n",
        "    for k in [\"停止\", \"徐行\", \"進行\"]:\n",
        "        rs = reasons[k]\n",
        "        if rs:\n",
        "            lines.append(f\"- **{k}**\")\n",
        "            for r in rs:\n",
        "                lines.append(f\"  - {r}\")\n",
        "    lines.append(\"\")\n",
        "    lines.append(\"## 観察（caption）\")\n",
        "    lines.append(f\"> {caption}\")\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "# --- State to keep last inference for saving ---\n",
        "LAST = {\"image_path\": None, \"record\": None}\n",
        "\n",
        "def analyze(image: Image.Image):\n",
        "    if image is None:\n",
        "        return \"画像がありません。\", gr.update(visible=True)\n",
        "    cap = caption_image(image)\n",
        "    obs, scores, reasons, action = distill_and_score(cap)\n",
        "\n",
        "    panel = render_panel(cap, scores, reasons, action)\n",
        "\n",
        "    # 一時保存（後で「保存」ボタンでDriveへ）\n",
        "    tmp_id = datetime.now().strftime(\"%Y%m%d_%H%M%S\") + \"_\" + uuid.uuid4().hex[:8]\n",
        "    img_path = os.path.join(IMG_DIR, f\"{tmp_id}.jpg\")\n",
        "    image.convert(\"RGB\").save(img_path, quality=92)\n",
        "\n",
        "    record = {\n",
        "        \"id\": tmp_id,\n",
        "        \"timestamp\": datetime.now().isoformat(),\n",
        "        \"image_path\": img_path,\n",
        "        \"caption\": cap,\n",
        "        \"observations\": obs,\n",
        "        \"scores\": scores,\n",
        "        \"reasons\": reasons,\n",
        "        \"action\": action,\n",
        "        \"rating_action\": None,     # あとで入力\n",
        "        \"rating_grounded\": None,   # あとで入力\n",
        "        \"comment\": \"\",\n",
        "    }\n",
        "    LAST[\"image_path\"] = img_path\n",
        "    LAST[\"record\"] = record\n",
        "\n",
        "    return panel, gr.update(visible=True)\n",
        "\n",
        "def save_feedback(rating_action, rating_grounded, comment):\n",
        "    if LAST[\"record\"] is None:\n",
        "        return \"まだ推論結果がありません。先に画像を入れて「判定」を押してね。\"\n",
        "\n",
        "    rec = dict(LAST[\"record\"])\n",
        "    rec[\"rating_action\"] = int(rating_action)\n",
        "    rec[\"rating_grounded\"] = int(rating_grounded)\n",
        "    rec[\"comment\"] = (comment or \"\").strip()\n",
        "\n",
        "    with open(LOG_PATH, \"a\", encoding=\"utf-8\") as f:\n",
        "        f.write(json.dumps(rec, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "    return f\"保存しました ✅\\n- 画像: {os.path.basename(rec['image_path'])}\\n- ログ: {LOG_PATH}\"\n",
        "\n",
        "# --- UI ---\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# 交通状況：純粋セマンティック空間（ライト版）\")\n",
        "    gr.Markdown(\"写真→構造化→スコア（停止/徐行/進行）→理由。あなたの評価をDriveへ蓄積。\")\n",
        "\n",
        "    with gr.Row():\n",
        "        img = gr.Image(type=\"pil\", label=\"街中で撮った写真を入れる\")\n",
        "        out_md = gr.Markdown(\"ここに結果が出ます\")\n",
        "\n",
        "    btn = gr.Button(\"判定（推論）\")\n",
        "\n",
        "    with gr.Accordion(\"あなたの評価（保存）\", open=True, visible=False) as acc:\n",
        "        gr.Markdown(\"**A: 結論は妥当？**（1=危険/間違い, 5=かなり妥当）\")\n",
        "        rating_action = gr.Slider(1, 5, value=3, step=1, label=\"A: 結論の妥当性\")\n",
        "        gr.Markdown(\"**B: 根拠は画像に基づいてる？**（1=妄想, 5=根拠明確）\")\n",
        "        rating_grounded = gr.Slider(1, 5, value=3, step=1, label=\"B: 根拠の実在性\")\n",
        "        comment = gr.Textbox(label=\"コメント（任意）\", placeholder=\"例：信号は写ってない／歩行者は実際いなかった など\", lines=2)\n",
        "        save_btn = gr.Button(\"Driveへ保存（画像＋JSONL）\")\n",
        "        save_msg = gr.Textbox(label=\"保存結果\", interactive=False)\n",
        "\n",
        "    btn.click(fn=analyze, inputs=img, outputs=[out_md, acc])\n",
        "    save_btn.click(fn=save_feedback, inputs=[rating_action, rating_grounded, comment], outputs=save_msg)\n",
        "\n",
        "demo.launch(share=True)\n"
      ]
    }
  ]
}